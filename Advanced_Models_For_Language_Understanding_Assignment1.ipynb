{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["7o3Mz8zr3foD"],"gpuType":"T4","include_colab_link":true},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11580317,"sourceType":"datasetVersion","datasetId":7260903},{"sourceId":11580322,"sourceType":"datasetVersion","datasetId":7260907}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"072a8241-d79e-4056-af84-28a0b1ec89d4","cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/AviRahimov/AMFLU_Assignment1/blob/main/Advanced_Models_For_Language_Understanding_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"id":"f27024dc-c7d3-4cfe-a614-16d1738a451b","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:00:51.205161Z","iopub.execute_input":"2025-05-08T15:00:51.205357Z","iopub.status.idle":"2025-05-08T15:00:53.108096Z","shell.execute_reply.started":"2025-05-08T15:00:51.205340Z","shell.execute_reply":"2025-05-08T15:00:53.107437Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/train-df/train.csv\n/kaggle/input/test-no-target/test_no_target.csv\n","output_type":"stream"}],"execution_count":1},{"id":"f0a61948","cell_type":"markdown","source":"# üîπ Assignment 1: Seq2Seq Model for Sentence Unshuffling\nIn this assignment, you'll implement a basic **Sequence-to-Sequence (Seq2Seq)** neural network using PyTorch.\n\n### üéØ **Your goal:**\nGiven a sentence whose words have been shuffled randomly, your model must reconstruct the original sentence.\n\n**Example:**\n\n| Input (shuffled) | Output (original) |\n|-----------------|------------------|\n| `mat the on sat cat The` | `The cat sat on the mat` |","metadata":{"id":"f0a61948"}},{"id":"37546a90","cell_type":"markdown","source":"## üîπ Why this task?\nThis simple yet non-trivial task demonstrates how language models learn word-order and syntactic structures.\nFrom a psycholinguistic viewpoint, sentence reconstruction taps into:\n\n- **Working memory**: The model must hold multiple words and reorder them meaningfully.\n- **Syntax and semantics**: Reordering depends on syntactic constraints and semantic coherence.","metadata":{"id":"37546a90"}},{"id":"FmlLBejDCw6X","cell_type":"markdown","source":"## üîπ Quick Summary of PyTorch Workflow\n\nThe general workflow when working with on deep learning with PyTorch usually involves these steps:\n\n1. **Prepare your data**:\n    - Define your dataset by subclassing `torch.utils.data.Dataset`.\n    - Use a `DataLoader` to iterate efficiently over the dataset in batches.\n    - Tokenization - select tokenization method and tokenize your data.\n\n2. **Define your model**:\n    - Create a model class by subclassing `nn.Module`.\n    - Define model layers in `__init__`.\n    - Define how data flows through the layers in the `forward()` method.\n\n\n3. **Training**:\n    - Select an appropriate loss function (`nn.CrossEntropyLoss`, `nn.MSELoss`, etc.).\n    - Choose an optimizer (`optim.Adam`, `optim.SGD`, etc.).\n    - **Training Loop** -- For each batch:\n        1. Pass input data through your model to produce predictions (logits).\n        2. Compute the loss w.r.t. the gold label (target).\n        3. Perform backpropagation (`loss.backward()`) to calculate gradients of all model parameters.\n        4. Update the model parameters with your optimizer (`optimizer.step()`).\n        5. Reset gradients (`optimizer.zero_grad()`).\n\nThis structured workflow helps streamline model development and makes training neural networks clear and efficient.\n\nThis notebook will walk you through this process - you need to learn it and the complete the missing code segment marked with a `#TODO` comment.","metadata":{"id":"FmlLBejDCw6X"}},{"id":"IMXO6OkGIU1j","cell_type":"markdown","source":"## üîπ Step 0: One-time Preparations\n\n### Step 0.1: Install Python Dependencies","metadata":{"id":"IMXO6OkGIU1j"}},{"id":"hKyvKyjaIgWA","cell_type":"code","source":"%pip install torch pandas scikit-learn","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKyvKyjaIgWA","outputId":"219975a9-d3b6-4792-b691-4e9396ee1ffd","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:02:57.945104Z","iopub.execute_input":"2025-04-27T13:02:57.945484Z","iopub.status.idle":"2025-04-27T13:04:25.554072Z","shell.execute_reply.started":"2025-04-27T13:02:57.945465Z","shell.execute_reply":"2025-04-27T13:04:25.553324Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"id":"c7573a39","cell_type":"markdown","source":"### Step 0.2: Download the Dataset\nDownload the provided dataset file (`train.csv`) from the following link:\n\n[train.csv](https://drive.google.com/file/d/1eHBj_mdKjPfj_NuXy0zCG5IkQMJLGpPM/view?usp=sharing)\n\nThen upload the file to your Colab notebook or Jupyter environment.","metadata":{"id":"c7573a39"}},{"id":"8d22c22e","cell_type":"markdown","source":"## üîπ Step 1: Prepare Data","metadata":{"id":"8d22c22e"}},{"id":"a70075c2","cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nfrom sklearn.model_selection import train_test_split\n\nrandom_seed = 123\nrandom.seed(random_seed)\ntorch.manual_seed(random_seed)\n\ndf = pd.read_csv('/kaggle/input/train-df/train.csv') # Kaggle use\n# df = pd.read_csv('train.csv') # use this if you run locally and have the train.csv file\ndf.head()","metadata":{"id":"a70075c2","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"aefa2069-a3b2-4c92-a109-e7cc752ba523","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:01:04.290343Z","iopub.execute_input":"2025-05-08T15:01:04.291131Z","iopub.status.idle":"2025-05-08T15:01:06.748699Z","shell.execute_reply.started":"2025-05-08T15:01:04.291095Z","shell.execute_reply":"2025-05-08T15:01:06.747917Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                     input_sentence  \\\n0           0           to think need we about. That's something   \n1           1          is mountains. the up moon coming over The   \n2           2  committee. the The through Congressmen bill ra...   \n3           3            careful late I'll to never again. be be   \n4           4           please.\" gifts, \"No The said, invitation   \n\n                                     target_sentence  \n0           That's something we need to think about.  \n1          The moon is coming up over the mountains.  \n2  The Congressmen rammed the bill through commit...  \n3            I'll be careful never to be late again.  \n4           The invitation said, \"No gifts, please.\"  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>input_sentence</th>\n      <th>target_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>to think need we about. That's something</td>\n      <td>That's something we need to think about.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>is mountains. the up moon coming over The</td>\n      <td>The moon is coming up over the mountains.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>committee. the The through Congressmen bill ra...</td>\n      <td>The Congressmen rammed the bill through commit...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>careful late I'll to never again. be be</td>\n      <td>I'll be careful never to be late again.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>please.\" gifts, \"No The said, invitation</td>\n      <td>The invitation said, \"No gifts, please.\"</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"id":"c21b2edd","cell_type":"code","source":"train_df, dev_df = train_test_split(df, test_size=0.1, random_state=42)\nprint(f\"Training examples: {len(train_df)}\")\nprint(f\"Development examples: {len(dev_df)}\")","metadata":{"id":"c21b2edd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca8d3247-fce5-48d0-d1e4-4971a52f4f0e","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:02:22.642102Z","iopub.execute_input":"2025-05-08T15:02:22.642378Z","iopub.status.idle":"2025-05-08T15:02:22.658156Z","shell.execute_reply.started":"2025-05-08T15:02:22.642358Z","shell.execute_reply":"2025-05-08T15:02:22.657594Z"}},"outputs":[{"name":"stdout","text":"Training examples: 31500\nDevelopment examples: 3500\n","output_type":"stream"}],"execution_count":3},{"id":"JRGMPu8eKVnI","cell_type":"markdown","source":"#### Pedagogical Note: **Why do we split train data into training and development (dev) sets?**\n\nWhen developing machine learning models, we want to ensure our model not only performs well on the data it has seen during training but also generalizes effectively to **new, unseen data**.\n\n- **Training set**:  \n  Used by the model to learn patterns. This is the data your model sees repeatedly during the training process.\n\n- **Development (dev) set** *(also known as validation set)*:  \n  Used to evaluate the model's performance on unseen examples during training. By checking the model periodically against the dev set, we can identify and prevent **overfitting**‚Äîwhen the model performs excellently on training data but poorly on new examples.\n\nThus, by splitting the data, we ensure our model truly learns generalizable patterns rather than memorizing the specific examples it trained on.\n","metadata":{"id":"JRGMPu8eKVnI"}},{"id":"9df6d543","cell_type":"code","source":"# Handle Vocabulary and Tokenization\nfrom collections import Counter\n\ndef tokenize(sentence):\n    return sentence.lower().split()\n\ncounter = Counter()\nfor sentence in train_df['input_sentence']:\n    counter.update(tokenize(sentence))\n\n# Special Tokens\nPAD = '<PAD>'\nSOS = '<SOS>'\nEOS = '<EOS>'\nUNK = '<UNK>'   # to handle out-of-vocabulary words\n\nwords = [PAD, SOS, EOS, UNK] + [w for w, c in counter.items() if c >= 1] # Changed the c >= 2 to c >= 1 to prevent <UNK> prediction\n# we maintain mapping between words (vocabulary entries) and their ids\nword2idx = {w: i for i, w in enumerate(words)}\nidx2word = {i: w for w, i in word2idx.items()}\n\nvocab_size = len(word2idx)\nprint(f\"Vocabulary size: {vocab_size}\")\n\ndef encode_sentence(sentence: str, word2idx, max_len):\n    # Replace sentence string with a fixed-length list of ints (token_ids with padding)\n    tokens = tokenize(sentence)\n    token_ids = [word2idx.get(w, word2idx[UNK]) for w in tokens]\n    token_ids = token_ids[:max_len-1]\n    token_ids.append(word2idx[EOS])\n    padding = [word2idx[PAD]] * (max_len - len(token_ids))\n    return token_ids + padding","metadata":{"id":"9df6d543","colab":{"base_uri":"https://localhost:8080/"},"outputId":"759df90d-c345-40f5-8935-bc17bdcfcdaa","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:02:35.580367Z","iopub.execute_input":"2025-05-08T15:02:35.580887Z","iopub.status.idle":"2025-05-08T15:02:35.654536Z","shell.execute_reply.started":"2025-05-08T15:02:35.580865Z","shell.execute_reply":"2025-05-08T15:02:35.653767Z"}},"outputs":[{"name":"stdout","text":"Vocabulary size: 17063\n","output_type":"stream"}],"execution_count":4},{"id":"9a1b859c","cell_type":"code","source":"# Custom Dataset class for sentence-to-sentence mapping\nclass SentenceDataset(torch.utils.data.Dataset):\n    def __init__(self, df, word2idx, max_len):\n        # Store input and target sentences as lists of strings\n        self.input_sentences = df['input_sentence'].tolist()\n        self.target_sentences = df['target_sentence'].tolist()\n        self.word2idx = word2idx  # mapping from word to index\n        self.max_len = max_len    # maximum length of sentence (for padding)\n\n    def __len__(self):\n        # Return number of examples in the dataset\n        return len(self.input_sentences)\n\n    def __getitem__(self, idx):\n        # Encode both input and target sentences to fixed-length tensors of token IDs\n        src = encode_sentence(self.input_sentences[idx], self.word2idx, self.max_len)\n        trg = encode_sentence(self.target_sentences[idx], self.word2idx, self.max_len)\n        return torch.tensor(src), torch.tensor(trg)  # return as PyTorch tensors\n\n# Define batch size and maximum sentence length\nbatch_size = 32\nmax_len = 50  # All sequences will be padded/truncated to this length\n\n# Create training dataset and dataloader\ntrain_dataset = SentenceDataset(train_df, word2idx, max_len)\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True\n)\n# DataLoader loads batches from the dataset and optionally shuffles them\n\n# Create development (validation) dataset and dataloader\ndev_dataset = SentenceDataset(dev_df, word2idx, max_len)\ndev_loader = torch.utils.data.DataLoader(\n    dev_dataset, batch_size=batch_size\n)\n","metadata":{"id":"9a1b859c","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:11:05.717278Z","iopub.execute_input":"2025-05-08T15:11:05.718056Z","iopub.status.idle":"2025-05-08T15:11:05.727876Z","shell.execute_reply.started":"2025-05-08T15:11:05.718030Z","shell.execute_reply":"2025-05-08T15:11:05.727087Z"}},"outputs":[],"execution_count":5},{"id":"Wm8yYkpes3u3","cell_type":"code","source":"# Get one batch of (src, trg) from the DataLoader\nsrc_batch, trg_batch = next(iter(train_loader))\n\n# Print their shapes\nprint(\"src_batch.shape =\", src_batch.shape)\nprint(\"trg_batch.shape =\", trg_batch.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wm8yYkpes3u3","outputId":"511f32d7-1eef-4fcf-8f76-3c175741bb9b","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:11:08.358586Z","iopub.execute_input":"2025-05-08T15:11:08.358863Z","iopub.status.idle":"2025-05-08T15:11:08.521996Z","shell.execute_reply.started":"2025-05-08T15:11:08.358841Z","shell.execute_reply":"2025-05-08T15:11:08.521233Z"}},"outputs":[{"name":"stdout","text":"src_batch.shape = torch.Size([32, 50])\ntrg_batch.shape = torch.Size([32, 50])\n","output_type":"stream"}],"execution_count":6},{"id":"7o3Mz8zr3foD","cell_type":"markdown","source":"## PyTorch Quick Reference\n\nSince this is your first encounter with PyTorch in the course, here's a short summary of essential PyTorch classes used in this notebook:\n","metadata":{"id":"7o3Mz8zr3foD"}},{"id":"hKLOmTr0BHyk","cell_type":"markdown","source":"\n---\n### ‚úÖ torch.utils.data.Dataset\n#### What is it?\n\nAn abstract class representing your dataset. It lets you define exactly how to access and prepare each data point.\n\n#### How to use it?\n\nYou subclass it and implement two methods:\n\n`__len__(self)`: returns the size of your dataset.\n\n`__getitem__(self, index)`: returns one data point (input-target pair).\n\n#### Why do we use it?\nIt provides a clean way to structure your data and feed it systematically into your model.\n\n---\n### ‚úÖ torch.utils.data.DataLoader\n#### What is it?\nA utility that takes a Dataset object and provides an iterator over it.\n\n#### How to use it?\nSpecify batch size, shuffle options, and more:\n\n```python\nloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n```\n#### Why do we use it?\nIt handles batching, shuffling, and efficient parallel data loading automatically‚Äîmaking your training loop concise and efficient.\n\n---\n### ‚úÖ torch.nn.Module\n#### What is it?\nThe base class for all neural network models in PyTorch. Every model you build inherits from it.\n\n#### How to use it?\nYou subclass it, define your layers in the constructor (`__init__`), and specify the forward pass in the `forward()` method:\n\n```python\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.linear = nn.Linear(10, 1)\n    \n    def forward(self, x):\n        return self.linear(x)\n```\n#### Why do we use it?\nIt manages model parameters, handles the forward computation, and simplifies tasks such as moving models to GPU or tracking gradients automatically.\n\n\n","metadata":{"id":"hKLOmTr0BHyk"}},{"id":"VlTEAM4y3FA0","cell_type":"markdown","source":"## üîπ Step 2: Define Model","metadata":{"id":"VlTEAM4y3FA0"}},{"id":"DuXH8zUee6Ud","cell_type":"markdown","source":"### Building blocks - Enocder and Decoder","metadata":{"id":"DuXH8zUee6Ud"}},{"id":"b174954f-ab17-4c37-ba1b-056b29925e8b","cell_type":"markdown","source":"## 3. Model Architecture: Encoder-Decoder\n\nOur model uses an Encoder-Decoder setup with GRU (Gated Recurrent Unit) layers.\n\n### a. `EncoderRNN(nn.Module)`\n\n**Purpose**: To process an input sequence and summarize it into a fixed-size \"context vector\" (the GRU's final hidden state).\n\n-   **Key Layers**:\n    -   `nn.Embedding`: Converts input token IDs to dense vectors.\n    -   `nn.GRU`: Processes the sequence of embeddings.\n-   **`forward(input, hidden)`**:\n    1.  Takes input token IDs `(seq_len, batch_size)` and an initial `hidden` state.\n    2.  Embeds input IDs.\n    3.  Passes embeddings through GRU.\n    4.  Returns all GRU outputs and the final `hidden` state (context vector).\n-   **`init_hidden(batch_size)`**: Creates an initial zero hidden state for the GRU.\n\n### b. `DecoderRNN(nn.Module)`\n\n**Purpose**: To take the Encoder's context vector and generate an output sequence, one token at a time.\n\n-   **Key Layers**:\n    -   `nn.Embedding`: Embeds the current input token for decoding.\n    -   `nn.GRU`: Processes the current token and hidden state.\n    -   `nn.Linear` (`self.out`): Maps GRU output to vocabulary scores (logits).\n-   **`forward(input, hidden)`** (processes one decoding step):\n    1.  Takes the current `input` token ID `(batch_size)` and current `hidden` state.\n    2.  Embeds the `input` token.\n    3.  Passes the embedding and `hidden` state through the GRU.\n    4.  The GRU output is fed to the `nn.Linear` layer to get `output` logits.\n    5.  Returns `output` logits `(batch_size, vocab_size)` and the updated `hidden` state.\n\n### c. `Seq2Seq(nn.Module)`\n\n**Purpose**: Combines the Encoder and Decoder into a single trainable model.\n\n-   **`forward(src, trg)`**:\n    1.  **Encode**: The `src` (input) sequence `(batch_size, seq_len)` is passed through the `self.encoder`. The encoder's final hidden state becomes the decoder's initial hidden state (context).\n    2.  **Decode (with Teacher Forcing)**:\n        -   The decoder starts with an `<SOS>` token as input.\n        -   It iterates for `trg_len` (target sequence length) steps:\n            -   The decoder generates `output` logits and an updated `hidden` state.\n            -   These logits are stored.\n            -   For the next step, the *actual* token from the `trg` sequence is fed as input to the decoder (this is \"Teacher Forcing\").\n    3.  **Return**: A tensor `(batch_size, trg_len, vocab_size)` of output logits for each token in the target sequence.","metadata":{}},{"id":"6c990ab2","cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, vocab_size, embedding_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size  # Store hidden_size\n\n        # Define layers: embedding layer and GRU layer\n        self.embedding = nn.Embedding(vocab_size, embedding_size)\n        \n        # GRU layer: input_size=embedding_size, hidden_size=hidden_size\n        # batch_first=False because input shape is expected as (seq_len, batch_size)\n        self.gru = nn.GRU(embedding_size, hidden_size, batch_first=False)\n\n    def forward(self, input, hidden):\n        \"\"\"\n        input: (seq_len, batch_size) - token indices for input sentence\n        hidden: (1, batch_size, hidden_size) - initial hidden state for GRU (num_layers*num_directions, batch, hidden_size)\n        Returns:\n            output: all hidden states for the input sequence (seq_len, batch_size, hidden_size)\n            hidden: final hidden state (1, batch_size, hidden_size)\n        \"\"\"\n        # Embed the input sequence\n        # input shape: (seq_len, batch_size)\n        # embedded shape: (seq_len, batch_size, embedding_size)\n        embedded = self.embedding(input)\n\n        # Pass embedded input and hidden state to GRU\n        # output shape: (seq_len, batch_size, hidden_size)\n        # hidden shape: (1, batch_size, hidden_size) (since num_layers=1, num_directions=1)\n        output, hidden = self.gru(embedded, hidden)\n        return output, hidden\n\n    def init_hidden(self, batch_size):\n        # Create initial hidden state tensor\n        # Shape: (num_layers*num_directions, batch_size, hidden_size)\n        # We use num_layers=1, num_directions=1 for GRU\n        # The tensor should be on the same device as the model parameters\n        device = next(self.parameters()).device\n        return torch.zeros(1, batch_size, self.hidden_size, device=device)\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, vocab_size, embedding_size, hidden_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size # Store hidden_size\n\n        # Define layers: embedding, GRU, and a linear output layer\n        self.embedding = nn.Embedding(vocab_size, embedding_size)\n        # GRU layer: input_size=embedding_size, hidden_size=hidden_size\n        # batch_first=False, but we'll process seq_len=1 at a time\n        self.gru = nn.GRU(embedding_size, hidden_size, batch_first=False)\n        # Linear layer to map GRU output to vocabulary size\n        # This layer is named 'out' to match self.decoder.out.out_features in Seq2Seq\n        self.out = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, input, hidden):\n        \"\"\"\n        input: (batch_size) - current token index at this decoding step\n        hidden: (1, batch_size, hidden_size) - current hidden state from GRU\n        Returns:\n            output: prediction for the next word (before softmax) (batch_size, vocab_size)\n            hidden: updated hidden state (1, batch_size, hidden_size)\n        \"\"\"\n        # Add a sequence length dimension to the input (seq_len=1)\n        # input shape: (batch_size) -> (1, batch_size)\n        input = input.unsqueeze(0)\n\n        # Embed the input token\n        # embedded shape: (1, batch_size, embedding_size)\n        embedded = self.embedding(input)\n\n        # Pass embedded input and hidden state to GRU\n        # gru_output shape: (1, batch_size, hidden_size) (seq_len=1)\n        # hidden shape: (1, batch_size, hidden_size)\n        gru_output, hidden = self.gru(embedded, hidden)\n\n        # Remove the sequence length dimension before passing to the linear layer\n        # gru_output shape: (1, batch_size, hidden_size) -> (batch_size, hidden_size)\n        gru_output_squeezed = gru_output.squeeze(0)\n\n        # Get predictions (logits) from the linear layer\n        # output shape: (batch_size, vocab_size)\n        output = self.out(gru_output_squeezed)\n        return output, hidden","metadata":{"id":"6c990ab2","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:30:09.652788Z","iopub.execute_input":"2025-05-08T15:30:09.653518Z","iopub.status.idle":"2025-05-08T15:30:09.664095Z","shell.execute_reply.started":"2025-05-08T15:30:09.653466Z","shell.execute_reply":"2025-05-08T15:30:09.663281Z"}},"outputs":[],"execution_count":7},{"id":"08f70b0d","cell_type":"code","source":"# Define Encoder & Decoder\nembedding_size = 64\nhidden_size = 128\n\nencoder = EncoderRNN(vocab_size, embedding_size, hidden_size)\ndecoder = DecoderRNN(vocab_size, embedding_size, hidden_size)\n\n# Sanity Checks\nsample_input, sample_target = next(iter(train_loader))\nencoder_hidden = encoder.init_hidden(sample_input.size(0))\n# not working since the the sample_input is with shape of (batch_size, seq_len) and not (seq_len, batch_size)\n# encoder_output, encoder_hidden = encoder(sample_input, encoder_hidden) \nencoder_output, encoder_hidden = encoder(sample_input.transpose(0, 1), encoder_hidden) # transpose to make it work\n\ndevice = next(encoder.parameters()).device # encoder and decoder tensors should be on the same device\ndecoder_input = torch.tensor([word2idx[SOS]] * sample_input.size(0), device=device)\ndecoder_hidden = encoder_hidden\n\ndecoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n\nprint(\"Encoder output shape:\", encoder_output.shape)\nprint(\"Decoder output shape:\", decoder_output.shape)","metadata":{"id":"08f70b0d","colab":{"base_uri":"https://localhost:8080/"},"outputId":"09bbbd84-a233-45d3-c65b-8a866f74f68c","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:34:14.435952Z","iopub.execute_input":"2025-05-08T15:34:14.436444Z","iopub.status.idle":"2025-05-08T15:34:14.503442Z","shell.execute_reply.started":"2025-05-08T15:34:14.436423Z","shell.execute_reply":"2025-05-08T15:34:14.502712Z"}},"outputs":[{"name":"stdout","text":"Encoder output shape: torch.Size([50, 32, 128])\nDecoder output shape: torch.Size([32, 17063])\n","output_type":"stream"}],"execution_count":11},{"id":"jQLknjFt-5bg","cell_type":"markdown","source":"### Seq2Seq model that wraps Encoder and Decoder together","metadata":{"id":"jQLknjFt-5bg"}},{"id":"JdusuF9w_Ea4","cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, sos_idx, device):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.sos_idx = sos_idx\n        self.device = device  # needed for creating new tensors like hidden states\n\n    def forward(self, src, trg):\n        \"\"\"\n        src: (batch_size, seq_len) - input sentence (shuffled)\n        trg: (batch_size, seq_len) - target sentence (original)\n        Returns:\n            outputs: tensor of shape (batch_size, seq_len, vocab_size)\n        \"\"\"\n        batch_size, trg_len = trg.shape\n        vocab_size = self.decoder.out.out_features\n\n        # Create an empty tensor to store decoder outputs\n        outputs = torch.zeros(batch_size, trg_len, vocab_size, device=self.device)\n\n        # Transpose inputs to match (seq_len, batch_size)\n        src = src.T\n        trg = trg.T\n\n        # Initialize hidden state on correct device\n        hidden = self.encoder.init_hidden(batch_size)\n\n        # Encode the input sentence\n        _, hidden = self.encoder(src, hidden)\n\n        # Start decoding with the <SOS> token\n        input = torch.full((batch_size,), self.sos_idx, device=self.device)\n\n        for t in range(trg_len):\n            output, hidden = self.decoder(input, hidden)\n            outputs[:, t, :] = output\n            input = trg[t]  # teacher forcing: feed the true token at each step\n\n        return outputs","metadata":{"id":"JdusuF9w_Ea4","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:34:19.330251Z","iopub.execute_input":"2025-05-08T15:34:19.330942Z","iopub.status.idle":"2025-05-08T15:34:19.339377Z","shell.execute_reply.started":"2025-05-08T15:34:19.330911Z","shell.execute_reply":"2025-05-08T15:34:19.338643Z"}},"outputs":[],"execution_count":12},{"id":"WAmJH-5feIkb","cell_type":"markdown","source":"## üîπ Step 3: Training","metadata":{"id":"WAmJH-5feIkb"}},{"id":"0lUGBZ7pd0Rw","cell_type":"code","source":"# define the training-loop function\ndef train_model(model, train_loader, dev_loader, optimizer, criterion, device, num_epochs=10):\n    model.to(device)\n    train_losses = []\n    dev_losses = []\n\n    for epoch in range(num_epochs):\n        model.train()\n        epoch_loss = 0\n\n        for src, trg in train_loader:\n            src, trg = src.to(device), trg.to(device)\n\n            optimizer.zero_grad()\n            output = model(src, trg)\n\n            # output: (batch, seq_len, vocab_size)\n            # trg: (batch, seq_len)\n            output = output.view(-1, output.shape[-1])  # shape: (batch * seq_len, vocab_size)\n            trg = trg.view(-1)                          # shape: (batch * seq_len)\n\n            # Compute the loss\n            loss = criterion(output, trg)\n\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n\n        train_losses.append(epoch_loss / len(train_loader))\n\n        # Evaluate on dev set\n        model.eval()\n        dev_loss = 0\n\n        with torch.no_grad():\n            for src, trg in dev_loader:\n                src, trg = src.to(device), trg.to(device)\n                output = model(src, trg)\n                output = output.view(-1, output.shape[-1])\n                trg = trg.view(-1)\n                loss = criterion(output, trg)\n                dev_loss += loss.item()\n\n        dev_losses.append(dev_loss / len(dev_loader))\n        print(f\"Epoch {epoch+1} | Train Loss: {train_losses[-1]:.4f} | Dev Loss: {dev_losses[-1]:.4f}\")\n\n    return train_losses, dev_losses","metadata":{"id":"0lUGBZ7pd0Rw","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:34:24.265333Z","iopub.execute_input":"2025-05-08T15:34:24.265628Z","iopub.status.idle":"2025-05-08T15:34:24.272827Z","shell.execute_reply.started":"2025-05-08T15:34:24.265601Z","shell.execute_reply":"2025-05-08T15:34:24.272028Z"}},"outputs":[],"execution_count":13},{"id":"AqiWK2_-fOWF","cell_type":"code","source":"# Instantiate Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Seq2Seq(encoder, decoder, word2idx[SOS], device)\n\n# Choose optimizer and loss function\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss(ignore_index=word2idx[PAD])\n\n# Run training\ntrain_losses, dev_losses = train_model(\n    model, train_loader, dev_loader,\n    optimizer, criterion, device,\n    num_epochs=10\n)","metadata":{"id":"AqiWK2_-fOWF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d6553317-0778-4e58-dfa9-ea18fb9ad3e3","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:34:30.530414Z","iopub.execute_input":"2025-05-08T15:34:30.530986Z","iopub.status.idle":"2025-05-08T15:45:25.194549Z","shell.execute_reply.started":"2025-05-08T15:34:30.530964Z","shell.execute_reply":"2025-05-08T15:45:25.193721Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 | Train Loss: 5.3817 | Dev Loss: 4.5139\nEpoch 2 | Train Loss: 4.0402 | Dev Loss: 3.9808\nEpoch 3 | Train Loss: 3.4575 | Dev Loss: 3.6867\nEpoch 4 | Train Loss: 3.0414 | Dev Loss: 3.4967\nEpoch 5 | Train Loss: 2.7024 | Dev Loss: 3.3670\nEpoch 6 | Train Loss: 2.4183 | Dev Loss: 3.2820\nEpoch 7 | Train Loss: 2.1734 | Dev Loss: 3.2342\nEpoch 8 | Train Loss: 1.9605 | Dev Loss: 3.1895\nEpoch 9 | Train Loss: 1.7722 | Dev Loss: 3.1574\nEpoch 10 | Train Loss: 1.6086 | Dev Loss: 3.1452\n","output_type":"stream"}],"execution_count":14},{"id":"k63dQnCoh3Zn","cell_type":"code","source":"# Helper - loss visualizations\nimport matplotlib.pyplot as plt\n\ndef plot_losses(train_losses, dev_losses):\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(dev_losses, label='Dev Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and Dev Loss over Epochs')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nplot_losses(train_losses, dev_losses)","metadata":{"id":"k63dQnCoh3Zn","colab":{"base_uri":"https://localhost:8080/","height":472},"outputId":"854dacab-5f8b-4c07-f6be-d1b1a3884136","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:45:28.453213Z","iopub.execute_input":"2025-05-08T15:45:28.453914Z","iopub.status.idle":"2025-05-08T15:45:28.746910Z","shell.execute_reply.started":"2025-05-08T15:45:28.453888Z","shell.execute_reply":"2025-05-08T15:45:28.746196Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":15},{"id":"aO0t5R_HkEvF","cell_type":"markdown","source":"### Pedagogical Note: Interpreting the Loss Plots üîç\n\nAfter training completes, you'll see two curves:\n\n- **Train Loss**: How well the model fits the training data.\n- **Dev Loss**: How well the model generalizes to unseen (validation) data.\n\nIdeally:\n- Both curves should **decrease over time**.\n- A small gap between them indicates **good generalization**.\n- If train loss decreases but dev loss increases, your model may be **overfitting**.\n\nUse these curves to decide if your model is learning stably and when to stop training.\n","metadata":{"id":"aO0t5R_HkEvF"}},{"id":"fSXqwoPDndhF","cell_type":"markdown","source":"## Step 4: Inference\nNow that you have a trained model, you can use it to solve your task on any new data points.\n\nComplete the code below for implementing a inference function for the model.","metadata":{"id":"fSXqwoPDndhF"}},{"id":"LOlykSQOoa_R","cell_type":"code","source":"def infer_sentences(shuffled_sentences, model, word2idx, idx2word, device, max_len=50):\n    \"\"\"\n    Generate predicted (unshuffled) sentences from a list of shuffled input sentences.\n\n    Args:\n        shuffled_sentences (List[str]): Sentences with words in randomized order.\n        model (Seq2Seq): Trained encoder-decoder model.\n        word2idx (Dict[str, int]): Mapping from words to vocabulary indices.\n        idx2word (Dict[int, str]): Mapping from indices to words.\n        device (torch.device): CPU or CUDA device for inference.\n        max_len (int): Maximum sentence length to decode.\n\n    Returns:\n        List[str]: Model's predicted sentences (as plain strings).\n    \"\"\"\n    model.eval()\n    predictions = []\n\n    sos_idx = word2idx['<SOS>']\n    eos_idx = word2idx['<EOS>']\n    pad_idx = word2idx['<PAD>']\n\n    with torch.no_grad(): # Disable gradients for inference as they are not needed.\n        for sentence in shuffled_sentences:\n            # First, process the input sentence:\n            # Tokenize, convert to IDs, pad, and convert to a tensor.\n            input_token_ids = encode_sentence(sentence, word2idx, max_len)\n            src_tensor = torch.tensor(input_token_ids, dtype=torch.long, device=device).unsqueeze(0) # Create a batch of 1.\n\n            # The encoder expects (seq_len, batch_size), so transposing the tensor.\n            src_tensor = src_tensor.T\n\n            # Now, encode the input sentence.\n            batch_size_for_inference = src_tensor.shape[1] # This will be 1 for single sentence inference.\n            # Initialize the encoder's hidden state.\n            encoder_hidden_init = model.encoder.init_hidden(batch_size_for_inference)\n            \n            # Pass the source tensor and initial hidden state to the encoder.\n            # Only the final hidden state (the context vector) from the encoder is needed for simple seq2seq.\n            _, encoder_final_hidden = model.encoder(src_tensor, encoder_hidden_init)\n\n            # Initialize the decoder.\n            # Use the encoder's final hidden state as the decoder's initial hidden state.\n            decoder_hidden = encoder_final_hidden\n            # Start decoding with the <SOS> token.\n            decoder_input_token = torch.tensor([sos_idx] * batch_size_for_inference, dtype=torch.long, device=device)\n\n            # Loop to generate the output sequence token by token.\n            decoded_token_ids = []\n            for _ in range(max_len): # Limit the decoding length to max_len to prevent infinite loops.\n                # Feed the current input token and hidden state to the decoder.\n                output_logits, decoder_hidden = model.decoder(decoder_input_token, decoder_hidden)\n                # The decoder returns logits (scores) over the vocabulary.\n\n                # Pick the token with the highest score (greedy decoding).\n                top_next_token_id = output_logits.argmax(1)\n\n                # If the model predicts the <EOS> token, decoding for this sentence is complete.\n                if top_next_token_id.item() == eos_idx:\n                    break\n\n                # Otherwise, add the predicted token ID to the list.\n                decoded_token_ids.append(top_next_token_id.item())\n                # The predicted token becomes the input for the next decoding step.\n                decoder_input_token = top_next_token_id\n\n            # Finally, convert the list of predicted token IDs back to words.\n            predicted_words = [idx2word[token_id] for token_id in decoded_token_ids]\n            predicted_sentence: str = \" \".join(predicted_words)\n            predictions.append(predicted_sentence)\n\n    return predictions","metadata":{"id":"LOlykSQOoa_R","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:52:25.898196Z","iopub.execute_input":"2025-05-08T15:52:25.898511Z","iopub.status.idle":"2025-05-08T15:52:25.906551Z","shell.execute_reply.started":"2025-05-08T15:52:25.898482Z","shell.execute_reply":"2025-05-08T15:52:25.905943Z"}},"outputs":[],"execution_count":22},{"id":"Ddv1mOKWqA9p","cell_type":"markdown","source":"\nNow, use the above inference function to generate prediction for the **test set**. You are provided with the test set shuffled sentences in [this downloadable file](https://drive.google.com/file/d/178mEesTW89Ooz_f5bb6sHBHjAkG4DWMV/view?usp=sharing). In your submission, you should run the inference function of the provided list of shuffled sentences, to attain a `predicted_test.csv` file. Typically, these predictions over the test set will be evaluated against their annotated labels (targets).  \n\nIf you want to assess the quality of current trained model, you can run inference on the dev set and evaluate on it using the function below:","metadata":{"id":"Ddv1mOKWqA9p"}},{"id":"SE0shbcytAE1","cell_type":"code","source":"def evaluate_sentence_predictions(predictions, targets):\n    \"\"\"\n    Compute exact match accuracy between predicted and target sentences (as strings).\n    Args:\n        predictions (List[str])\n        targets (List[str])\n    Returns:\n        accuracy (float): percentage of exact string matches\n    \"\"\"\n    correct = 0\n    total = len(predictions)\n    for pred, true in zip(predictions, targets):\n        if pred.strip().lower() == true.strip().lower(): # Change it to ignore upper case\n            correct += 1\n    accuracy = correct / total * 100\n    print(f\"Exact match accuracy: {accuracy:.2f}%\")\n    return accuracy","metadata":{"id":"SE0shbcytAE1","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:52:27.657339Z","iopub.execute_input":"2025-05-08T15:52:27.658070Z","iopub.status.idle":"2025-05-08T15:52:27.662415Z","shell.execute_reply.started":"2025-05-08T15:52:27.658044Z","shell.execute_reply":"2025-05-08T15:52:27.661721Z"}},"outputs":[],"execution_count":23},{"id":"0983f301-a42e-49a0-a297-3847845f97a1","cell_type":"code","source":"# Evalute the model on dev dataset\npredictions_for_input = infer_sentences(dev_df['input_sentence'], model, word2idx, idx2word, device)\nprint(\"Accuracy on dev:\")\naccuracy = evaluate_sentence_predictions(predictions_for_input, dev_df['target_sentence'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:52:28.645243Z","iopub.execute_input":"2025-05-08T15:52:28.645950Z","iopub.status.idle":"2025-05-08T15:52:38.612332Z","shell.execute_reply.started":"2025-05-08T15:52:28.645926Z","shell.execute_reply":"2025-05-08T15:52:38.611735Z"}},"outputs":[{"name":"stdout","text":"Accuracy on dev:\nExact match accuracy: 3.37%\n","output_type":"stream"}],"execution_count":24},{"id":"5574f78e-fffe-4a45-bb43-fd577dd35fad","cell_type":"markdown","source":"# Saving predictions file","metadata":{}},{"id":"a7c63928-5752-46a9-b0cf-7eb3604054f3","cell_type":"code","source":"# Define file paths\ntest_data_path = '/kaggle/input/test-no-target/test_no_target.csv'\noutput_csv_path = '/kaggle/working/seq2seq_predictions.csv'\n\n# Load the test data\ntry:\n    test_df = pd.read_csv(test_data_path)\n    print(f\"Test data loaded successfully from {test_data_path}\")\n    print(f\"Test data shape: {test_df.shape}\")\n    print(\"Test data columns:\", test_df.columns.tolist())\nexcept FileNotFoundError:\n    print(f\"ERROR: Test data file not found at {test_data_path}\")\n\n    input_sentences_list = test_df['input_sentence'].tolist()\n\n    # Generate predictions using infer_sentences function\n    print(f\"Generating predictions for {len(input_sentences_list)} sentences...\")\n    # Ensure the model is on the correct device if not already\n    model.to(device)\n    \n    # Call the inference function\n    predicted_sentences_list = infer_sentences(\n        shuffled_sentences=input_sentences_list,\n        model=model,\n        word2idx=word2idx,\n        idx2word=idx2word,\n        device=device,\n    )\n    print(\"Predictions generated.\")\n\n    # Create a new DataFrame for the output\n    output_df = pd.DataFrame({\n        'input_sentence': input_sentences_list,  # The original sentences from the test set\n        'prediction_sentence': predicted_sentences_list\n    })\n\n    # Save the DataFrame to a CSV file\n    try:\n        output_df.to_csv(output_csv_path, index=False)\n        print(f\"Predictions successfully saved to {output_csv_path}\")\n        \n        # Display the first 5 predictions to see if the predictions make sense\n        print(\"\\nFirst 5 predictions:\")\n        print(output_df.head())\n    except Exception as e:\n        print(f\"ERROR: Could not save predictions to {output_csv_path}. Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:56:40.088562Z","iopub.execute_input":"2025-05-08T15:56:40.089558Z","iopub.status.idle":"2025-05-08T15:56:54.366288Z","shell.execute_reply.started":"2025-05-08T15:56:40.089528Z","shell.execute_reply":"2025-05-08T15:56:54.365526Z"}},"outputs":[{"name":"stdout","text":"Test data loaded successfully from /kaggle/input/test-no-target/test_no_target.csv\nTest data shape: (5000, 2)\nTest data columns: ['Unnamed: 0', 'input_sentence']\nGenerating predictions for 5000 sentences...\nPredictions generated.\nPredictions successfully saved to /kaggle/working/seq2seq_predictions.csv\n\nFirst 5 predictions:\n                                      input_sentence  \\\n0  often play you when school? in high basketball...   \n1                          what at I do. work I hard   \n2                              prefer to sit down. I   \n3  book gave the My is This yesterday. uncle a me...   \n4  are There of books English lot a in library. this   \n\n                                 prediction_sentence  \n0  how many times you were when you use any other...  \n1                i am looking forward at my brother.  \n2                            i prefer to drink golf.  \n3  my house is my best friend i bought my place f...  \n4      there are a lot of books in any other things.  \n","output_type":"stream"}],"execution_count":25},{"id":"m9PRjqHkt50Z","cell_type":"markdown","source":"# üîÅ Stage 2: Add Attention to Your Seq2Seq Model\n\nIn this stage, you'll implement a new model: **`Seq2SeqWithAttention`**.  \nThe goal is to improve your decoder by allowing it to \"attend\" to relevant parts of the encoder's outputs at each decoding step.\n\n### üß† Why Attention?\nThe encoder compresses the entire input sentence into a single hidden state. This limits performance, especially on long sentences.\n\nWith attention, the decoder **dynamically focuses on different encoder outputs**, depending on what it's trying to generate.\n\n---\n\n### üîß What You Need to Implement:\nYou will create a new class `Seq2SeqWithAttention`, similar to `Seq2Seq`, but with the following differences:\n\n1. At each decoding step, compute **attention scores** over all encoder hidden states.\n2. Use those scores to compute a **context vector** (weighted sum of encoder outputs).\n3. Feed the context vector into the decoder along with the embedding of the current input token.\n\n---\n\n### üìå Tip: Dot-Product Attention\nA simple form of attention you can implement is dot-product attention:\n\n```python\nscore_t = dot(h_dec_t, h_enc_i) weights = softmax(score_t over i) context_t = sum_i weights[i] * h_enc_i\n```\n\nYou'll apply this at every decoder time step.\n","metadata":{"id":"m9PRjqHkt50Z"}},{"id":"7642e93a-379f-41e0-9da6-a561a25aec65","cell_type":"code","source":"class DecoderRNNWithAttention(nn.Module):\n    def __init__(self, vocab_size, embedding_size, decoder_hidden_size, encoder_hidden_size):\n        super(DecoderRNNWithAttention, self).__init__()\n        self.decoder_hidden_size = decoder_hidden_size\n        self.encoder_hidden_size = encoder_hidden_size # This is the size of the context vector\n\n        self.embedding = nn.Embedding(vocab_size, embedding_size)\n\n        # The input to the GRU will be the concatenation of the embedded token\n        # and the context vector from the attention mechanism.\n        self.gru_input_size = embedding_size + encoder_hidden_size\n        self.gru = nn.GRU(self.gru_input_size, decoder_hidden_size, batch_first=False)\n\n        # The output layer maps from the decoder's hidden state to vocabulary size.\n        self.out = nn.Linear(decoder_hidden_size, vocab_size)\n\n    def forward(self, input_token, hidden, context_vector):\n        \"\"\"\n        input_token: (batch_size) - current token index at this decoding step\n        hidden: (1, batch_size, decoder_hidden_size) - current decoder hidden state\n        context_vector: (batch_size, encoder_hidden_size) - context vector from attention\n        Returns:\n            output: prediction for the next word (before softmax) (batch_size, vocab_size)\n            hidden: updated decoder hidden state (1, batch_size, decoder_hidden_size)\n        \"\"\"\n        # Add a sequence length dimension to the input_token (seq_len=1)\n        # input_token shape: (batch_size) -> (1, batch_size)\n        input_token_unsqueezed = input_token.unsqueeze(0)\n\n        # Embed the input token\n        # embedded shape: (1, batch_size, embedding_size)\n        embedded = self.embedding(input_token_unsqueezed)\n\n        # Unsqueeze context_vector to add sequence length dimension for concatenation\n        # context_vector shape: (batch_size, encoder_hidden_size) -> (1, batch_size, encoder_hidden_size)\n        context_vector_unsqueezed = context_vector.unsqueeze(0)\n\n        # Concatenate the embedded input token and the context vector along the feature dimension\n        # rnn_input shape: (1, batch_size, embedding_size + encoder_hidden_size)\n        rnn_input = torch.cat((embedded, context_vector_unsqueezed), dim=2)\n\n        # Pass concatenated input and hidden state to GRU\n        # gru_output shape: (1, batch_size, decoder_hidden_size) (seq_len=1)\n        # hidden shape: (1, batch_size, decoder_hidden_size)\n        gru_output, hidden = self.gru(rnn_input, hidden)\n\n        # Remove the sequence length dimension before passing to the linear layer\n        # gru_output_squeezed shape: (batch_size, decoder_hidden_size)\n        gru_output_squeezed = gru_output.squeeze(0)\n\n        # Get predictions (logits) from the linear layer\n        # output shape: (batch_size, vocab_size)\n        output = self.out(gru_output_squeezed)\n\n        return output, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:21:59.677838Z","iopub.execute_input":"2025-05-08T16:21:59.678137Z","iopub.status.idle":"2025-05-08T16:21:59.684850Z","shell.execute_reply.started":"2025-05-08T16:21:59.678117Z","shell.execute_reply":"2025-05-08T16:21:59.684302Z"}},"outputs":[],"execution_count":26},{"id":"nPvAmc_euarf","cell_type":"code","source":"import torch.nn.functional as F\n\nclass Seq2SeqWithAttention(nn.Module):\n    def __init__(self, encoder, decoder, sos_idx, device):\n        super(Seq2SeqWithAttention, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder # This is an instance of DecoderRNNWithAttention and not the Seq2Seq decoder\n        self.sos_idx = sos_idx\n        self.device = device\n\n        # For dot-product attention, if encoder_hidden_size == decoder_hidden_size,\n        # no additional layers are strictly needed.\n\n    def compute_attention(self, decoder_hidden, encoder_outputs):\n        \"\"\"\n        Computes attention scores and context vector using dot-product attention.\n        decoder_hidden: (1, batch_size, decoder_hidden_size) - current decoder GRU hidden state.\n        encoder_outputs: (seq_len, batch_size, encoder_hidden_size) - all encoder GRU outputs.\n                         Assumes decoder_hidden_size == encoder_hidden_size for dot product.\n\n        Returns:\n            context_vector: (batch_size, encoder_hidden_size)\n        \"\"\"\n        # decoder_hidden is (num_layers=1, batch, dec_hid_size)\n        # Permute decoder_hidden to be (batch, 1, dec_hid_size) for bmm\n        query = decoder_hidden.permute(1, 0, 2)\n\n        # encoder_outputs is (seq_len, batch, enc_hid_size)\n        # Permute encoder_outputs to be (batch, seq_len, enc_hid_size) for bmm\n        keys_values = encoder_outputs.permute(1, 0, 2)\n\n        # Calculate attention scores (energy)\n        # (batch, 1, dec_hid_size) @ (batch, enc_hid_size, seq_len) -> (batch, 1, seq_len)\n        # This requires dec_hid_size == enc_hid_size\n        energy = torch.bmm(query, keys_values.transpose(1, 2))\n\n        # Apply softmax to get attention weights\n        # dim=2 ensures softmax is over the source sequence length\n        # attention_weights shape: (batch, 1, seq_len)\n        attention_weights = F.softmax(energy, dim=2)\n\n        # Compute context vector: weighted sum of encoder_outputs (values)\n        # (batch, 1, seq_len) @ (batch, seq_len, enc_hid_size) -> (batch, 1, enc_hid_size)\n        context_vector_unsq = torch.bmm(attention_weights, keys_values)\n\n        # Squeeze context_vector to remove the middle dimension: (batch, enc_hid_size)\n        context_vector = context_vector_unsq.squeeze(1)\n\n        return context_vector\n\n    def forward(self, src, trg):\n        \"\"\"\n        src: (batch_size, seq_len) - input sentence\n        trg: (batch_size, seq_len) - target sentence\n        Returns:\n            outputs: tensor of shape (batch_size, seq_len, vocab_size)\n        \"\"\"\n        batch_size, trg_len = trg.shape\n        # Access vocab_size from the decoder's output layer\n        vocab_size = self.decoder.out.out_features\n\n        # Create an empty tensor to store decoder outputs\n        outputs = torch.zeros(batch_size, trg_len, vocab_size, device=self.device)\n\n        # Transpose inputs to match (seq_len, batch_size)\n        src = src.T\n        trg = trg.T\n\n        # Initialize encoder hidden state on correct device\n        encoder_initial_hidden = self.encoder.init_hidden(batch_size)\n\n        # Encode the input sentence\n        # encoder_outputs: (seq_len, batch_size, encoder_hidden_size)\n        # decoder_hidden: (1, batch_size, decoder_hidden_size) -> from encoder's final state\n        encoder_outputs, decoder_hidden = self.encoder(src, encoder_initial_hidden)\n\n        # Start decoding with the <SOS> token\n        input_token = torch.full((batch_size,), self.sos_idx, dtype=torch.long, device=self.device)\n\n        for t in range(trg_len):\n            # Compute context vector using attention\n            # decoder_hidden is the current hidden state of the decoder's GRU\n            # encoder_outputs are all hidden states from the encoder's GRU\n            context_vector = self.compute_attention(decoder_hidden, encoder_outputs)\n\n            # Decode one step\n            # The decoder now takes input_token, its own hidden state, and the context_vector\n            output, decoder_hidden = self.decoder(input_token, decoder_hidden, context_vector)\n\n            outputs[:, t, :] = output\n            input_token = trg[t]  # Teacher forcing: feed the true token at each step\n\n        return outputs","metadata":{"id":"nPvAmc_euarf","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:27:32.280918Z","iopub.execute_input":"2025-05-08T16:27:32.281203Z","iopub.status.idle":"2025-05-08T16:27:32.290733Z","shell.execute_reply.started":"2025-05-08T16:27:32.281183Z","shell.execute_reply":"2025-05-08T16:27:32.290137Z"}},"outputs":[],"execution_count":30},{"id":"3Fm5tMpGvBP1","cell_type":"markdown","source":"## üìù What You Need to Complete\n\n- Implement the `compute_attention()` method to compute a context vector from encoder outputs given the current (decoder) hidden state.\n- Update your `DecoderRNN` class so that it accepts and uses a context vector at every step:\n    - One option is to **concatenate** the context vector with the embedded input token before passing it to the RNN.\n    - Alternatively, you can feed the context into a projection layer together with the decoder hidden state.\n\n---\n\n### üìå Tip: Updated Decoder Signature\n\nYou may need to rewrite your decoder to look like:\n\n```python\ndef forward(self, input_token, hidden, context_vector):\n    ...\n```\n---\n> üí° **Note on Attention Implementation**\n\nYou are given flexibility in how you choose to implement the attention mechanism.\n\nYou may:\n- Implement the **basic dot-product attention** we discussed in class.\n- Or, explore a more expressive variant by adding a **linear projection** to the decoder hidden state or the encoder outputs ‚Äî borrowing an idea from self-attention in Transformers.\n\nAs long as your implementation uses the decoder hidden state to compute attention over the encoder outputs and forms a context vector, you're free to experiment and design the solution that makes most sense to you.\n","metadata":{"id":"3Fm5tMpGvBP1"}},{"id":"lsGSMPTxwj4a","cell_type":"markdown","source":"## 2.2 - Evaluate and Compare\n\nIn this stage, you should use your adapted `Seq2SeqWithAttention` model, train it and evaluate its performance (on the dev set).  ","metadata":{"id":"lsGSMPTxwj4a"}},{"id":"00a63831-5380-4c46-acdf-d019f5d6161c","cell_type":"code","source":"import copy # For deep copying model state\nimport torch.optim as optim\n\ndef train_model_with_early_stopping(model, train_loader, dev_loader, optimizer, criterion, device, num_epochs=15, patience=3):\n    \"\"\"\n    Trains the model with early stopping based on development set loss.\n\n    Args:\n        model (nn.Module): The PyTorch model to train.\n        train_loader (DataLoader): DataLoader for the training set.\n        dev_loader (DataLoader): DataLoader for the development/validation set.\n        optimizer (Optimizer): The optimizer.\n        criterion (Loss function): The loss function.\n        device (torch.device): The device to train on (e.g., 'cuda' or 'cpu').\n        num_epochs (int): Maximum number of epochs to train for.\n        patience (int): Number of epochs to wait for improvement before stopping.\n\n    Returns:\n        tuple: (train_losses, dev_losses)\n               train_losses: List of average training loss per epoch.\n               dev_losses: List of average development loss per epoch.\n               The function modifies the 'model' in-place to its best state.\n    \"\"\"\n    model.to(device)\n    train_losses = []\n    dev_losses = []\n\n    best_dev_loss = float('inf')\n    epochs_no_improve = 0\n    best_model_state = None # To store the state_dict of the best model\n\n    print(f\"Starting training with early stopping (patience={patience})...\")\n\n    for epoch in range(num_epochs):\n        model.train() # Set model to training mode\n        epoch_train_loss = 0\n\n        for src, trg in train_loader:\n            src, trg = src.to(device), trg.to(device)\n\n            optimizer.zero_grad()\n            output = model(src, trg) # Forward pass\n\n            # output shape: (batch, seq_len, vocab_size)\n            # trg shape: (batch, seq_len)\n            # Reshape for CrossEntropyLoss\n            output_flat = output.view(-1, output.shape[-1]) # (batch * seq_len, vocab_size)\n            trg_flat = trg.view(-1)                         # (batch * seq_len)\n\n            loss = criterion(output_flat, trg_flat)\n            loss.backward()\n            optimizer.step()\n            epoch_train_loss += loss.item()\n\n        avg_epoch_train_loss = epoch_train_loss / len(train_loader)\n        train_losses.append(avg_epoch_train_loss)\n\n        # Evaluation on development set\n        model.eval() # Set model to evaluation mode\n        epoch_dev_loss = 0\n        with torch.no_grad():\n            for src, trg in dev_loader:\n                src, trg = src.to(device), trg.to(device)\n                output = model(src, trg)\n                output_flat = output.view(-1, output.shape[-1])\n                trg_flat = trg.view(-1)\n                loss = criterion(output_flat, trg_flat)\n                epoch_dev_loss += loss.item()\n\n        avg_epoch_dev_loss = epoch_dev_loss / len(dev_loader)\n        dev_losses.append(avg_epoch_dev_loss)\n\n        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_epoch_train_loss:.4f} | Dev Loss: {avg_epoch_dev_loss:.4f}\")\n\n        # Early stopping logic\n        if avg_epoch_dev_loss < best_dev_loss:\n            best_dev_loss = avg_epoch_dev_loss\n            # Deep copy the model's state_dict to save the best version\n            best_model_state = copy.deepcopy(model.state_dict())\n            epochs_no_improve = 0\n            print(f\"  New best dev loss: {best_dev_loss:.4f}. Saving model state.\")\n        else:\n            epochs_no_improve += 1\n            print(f\"  Dev loss did not improve for {epochs_no_improve} epoch(s).\")\n\n        if epochs_no_improve >= patience:\n            print(f\"\\nEarly stopping triggered after {epoch+1} epochs.\")\n            print(f\"Loading best model state with dev loss: {best_dev_loss:.4f}\")\n            if best_model_state:\n                model.load_state_dict(best_model_state) # Load the best model parameters\n            break # Exit the training loop\n\n    # After the loop, if training finished without early stopping,\n    # ensure the model has the parameters of the best epoch if one was found.\n    # If early stopping occurred, the model is already set to its best state.\n    if best_model_state and epochs_no_improve < patience :\n        print(\"Training finished. Loading best model state achieved during training.\")\n        model.load_state_dict(best_model_state)\n\n    return train_losses, dev_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:57:03.485284Z","iopub.execute_input":"2025-05-08T16:57:03.485822Z","iopub.status.idle":"2025-05-08T16:57:03.498188Z","shell.execute_reply.started":"2025-05-08T16:57:03.485795Z","shell.execute_reply":"2025-05-08T16:57:03.497494Z"}},"outputs":[],"execution_count":35},{"id":"fc8d0c74-5635-4528-a191-94399160e5d9","cell_type":"code","source":"sos_idx = word2idx['<SOS>']\neos_idx = word2idx['<EOS>']\npad_idx = word2idx['<PAD>']\nunk_idx = word2idx['<UNK>']\n\n\ndef infer_sentences_with_attention(input_sentences, model, word2idx, idx2word, device, max_len=50):\n    \"\"\"\n    Generate predicted sentences using the Seq2SeqWithAttention model.\n    \"\"\"\n    model.eval()  # Set the model to evaluation mode\n    predictions = []\n\n    with torch.no_grad():  # Disable gradient calculations\n        for sentence_str in input_sentences:\n            # Preprocess the input sentence\n            token_ids = encode_sentence(sentence_str, word2idx, max_len) # Use your existing encode_sentence\n            src_tensor = torch.tensor(token_ids, dtype=torch.long, device=device).unsqueeze(0)  # (1, max_len)\n            src_tensor = src_tensor.T  # (max_len, 1) for encoder\n\n            # Encoding\n            batch_size_for_inference = src_tensor.shape[1] # Should be 1\n            encoder_initial_hidden = model.encoder.init_hidden(batch_size_for_inference)\n            encoder_outputs, decoder_hidden = model.encoder(src_tensor, encoder_initial_hidden)\n            # encoder_outputs: (max_len, 1, encoder_hidden_size)\n            # decoder_hidden: (1, 1, decoder_hidden_size) from encoder's final state\n\n            # Decoding loop\n            decoder_input_token = torch.tensor([sos_idx] * batch_size_for_inference, dtype=torch.long, device=device)\n            predicted_token_ids_for_sentence = []\n\n            for _ in range(max_len):\n                # Compute attention context vector\n                # decoder_hidden here is the previous step's decoder hidden state\n                context_vector = model.compute_attention(decoder_hidden, encoder_outputs)\n                # context_vector shape: (1, encoder_hidden_size)\n\n                # Pass to decoder\n                output_logits, decoder_hidden = model.decoder(decoder_input_token, decoder_hidden, context_vector)\n                # output_logits shape: (1, vocab_size)\n\n                # Greedy decoding\n                top_next_token_id = output_logits.argmax(1) # Shape: (1)\n\n                predicted_id = top_next_token_id.item()\n                if predicted_id == eos_idx:\n                    break\n                predicted_token_ids_for_sentence.append(predicted_id)\n                decoder_input_token = top_next_token_id # Use predicted token as next input\n\n            # Postprocessing\n            predicted_words = [idx2word.get(token_id, unk_idx) for token_id in predicted_token_ids_for_sentence]\n            predicted_sentence = \" \".join(predicted_words)\n            predictions.append(predicted_sentence)\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:27:33.439146Z","iopub.execute_input":"2025-05-08T16:27:33.439627Z","iopub.status.idle":"2025-05-08T16:27:33.447158Z","shell.execute_reply.started":"2025-05-08T16:27:33.439601Z","shell.execute_reply":"2025-05-08T16:27:33.446450Z"}},"outputs":[],"execution_count":31},{"id":"619dfb52-a282-4ff4-a2d2-b85df39bc5bf","cell_type":"code","source":"# Model Hyperparameters\nembedding_size = 128  # You can experiment with these\nencoder_hidden_size = 256\ndecoder_hidden_size = 256 # For dot-product attention, this often matches encoder_hidden_size\n\n# Instantiate Encoder and new Decoder (DecoderRNNWithAttention)\nprint(\"Initializing model components with attention...\")\nattn_encoder = EncoderRNN(vocab_size, embedding_size, encoder_hidden_size)\nattn_decoder = DecoderRNNWithAttention(vocab_size, embedding_size, decoder_hidden_size, encoder_hidden_size)\n\n# Instantiate Seq2SeqWithAttention model\n# Ensure device is defined\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nattn_model = Seq2SeqWithAttention(attn_encoder, attn_decoder, sos_idx, device)\nattn_model.to(device)\nprint(\"Seq2SeqWithAttention model created and moved to device:\", device)\n\n# Optimizer and Criterion\noptimizer_attn = optim.Adam(attn_model.parameters(), lr=0.001)\ncriterion_attn = nn.CrossEntropyLoss(ignore_index=word2idx[PAD])\n\n# Training parameters\nnum_epochs_attn = 20 # Max epochs, early stopping might finish sooner\nearly_stopping_patience = 3 # Number of epochs to wait for dev loss improvement\n\nprint(f\"\\nStarting training for Seq2SeqWithAttention model...\")\ntrain_losses_attn, dev_losses_attn = train_model_with_early_stopping(\n    attn_model,\n    train_loader,\n    dev_loader,\n    optimizer_attn,\n    criterion_attn,\n    device,\n    num_epochs=num_epochs_attn,\n    patience=early_stopping_patience\n)\nprint(\"Training with early stopping finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:57:05.680903Z","iopub.execute_input":"2025-05-08T16:57:05.681661Z","iopub.status.idle":"2025-05-08T17:11:37.222307Z","shell.execute_reply.started":"2025-05-08T16:57:05.681636Z","shell.execute_reply":"2025-05-08T17:11:37.221528Z"}},"outputs":[{"name":"stdout","text":"Initializing model components with attention...\nSeq2SeqWithAttention model created and moved to device: cuda\n\nStarting training for Seq2SeqWithAttention model...\nStarting training with early stopping (patience=3)...\nEpoch 1/20 | Train Loss: 4.9524 | Dev Loss: 3.8867\n  New best dev loss: 3.8867. Saving model state.\nEpoch 2/20 | Train Loss: 3.1934 | Dev Loss: 3.1688\n  New best dev loss: 3.1688. Saving model state.\nEpoch 3/20 | Train Loss: 2.3326 | Dev Loss: 2.8289\n  New best dev loss: 2.8289. Saving model state.\nEpoch 4/20 | Train Loss: 1.7006 | Dev Loss: 2.6650\n  New best dev loss: 2.6650. Saving model state.\nEpoch 5/20 | Train Loss: 1.2153 | Dev Loss: 2.5396\n  New best dev loss: 2.5396. Saving model state.\nEpoch 6/20 | Train Loss: 0.8474 | Dev Loss: 2.5141\n  New best dev loss: 2.5141. Saving model state.\nEpoch 7/20 | Train Loss: 0.5961 | Dev Loss: 2.4914\n  New best dev loss: 2.4914. Saving model state.\nEpoch 8/20 | Train Loss: 0.4259 | Dev Loss: 2.5068\n  Dev loss did not improve for 1 epoch(s).\nEpoch 9/20 | Train Loss: 0.3079 | Dev Loss: 2.5485\n  Dev loss did not improve for 2 epoch(s).\nEpoch 10/20 | Train Loss: 0.2245 | Dev Loss: 2.5799\n  Dev loss did not improve for 3 epoch(s).\n\nEarly stopping triggered after 10 epochs.\nLoading best model state with dev loss: 2.4914\nTraining with early stopping finished.\n","output_type":"stream"}],"execution_count":36},{"id":"7f6883da-45ed-4995-8c10-24c579b5e2ca","cell_type":"code","source":"plot_losses(train_losses_attn, dev_losses_attn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:11:44.764800Z","iopub.execute_input":"2025-05-08T17:11:44.765287Z","iopub.status.idle":"2025-05-08T17:11:44.914883Z","shell.execute_reply.started":"2025-05-08T17:11:44.765266Z","shell.execute_reply":"2025-05-08T17:11:44.914241Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":37},{"id":"32843328-6234-4dad-b14f-ebb1ad6ab489","cell_type":"code","source":"# --- Evaluate (if you have an evaluation function like evaluate_sentence_predictions) ---\nprint(\"\\nEvaluating on development set with attention model...\")\ndev_input_sentences = dev_df['input_sentence'].tolist()\ndev_target_sentences = dev_df['target_sentence'].tolist()\n\nattn_predictions_dev = infer_sentences_with_attention(\n    dev_input_sentences, attn_model, word2idx, idx2word, device, max_len=max_len # max_len from your setup\n)\n\naccuracy_attn = evaluate_sentence_predictions(attn_predictions_dev, dev_target_sentences)\nprint(f\"Accuracy on dev set with Attention Model: {accuracy_attn:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:12:02.140994Z","iopub.execute_input":"2025-05-08T17:12:02.141237Z","iopub.status.idle":"2025-05-08T17:12:17.390884Z","shell.execute_reply.started":"2025-05-08T17:12:02.141221Z","shell.execute_reply":"2025-05-08T17:12:17.390255Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating on development set with attention model...\nExact match accuracy: 14.54%\nAccuracy on dev set with Attention Model: 14.54%\n","output_type":"stream"}],"execution_count":38},{"id":"27dbba6d-deaf-48bc-b9e7-4fe01e2540e2","cell_type":"markdown","source":"# Saving Seq2Seq with Attention model predictions","metadata":{}},{"id":"2fe782e3-a05a-499b-a9bc-64a60542326b","cell_type":"code","source":"test_data_path_attn = '/kaggle/input/test-no-target/test_no_target.csv'\noutput_csv_path_attn = '/kaggle/working/seq2seq_with_attention_predictions.csv'\n\nprint(f\"\\nLoading test data from: {test_data_path_attn}\")\ntry:\n    test_df_attn = pd.read_csv(test_data_path_attn)\n    if 'input_sentence' not in test_df_attn.columns:\n        print(f\"ERROR: 'input_sentence' column not found in {test_data_path_attn}. Available: {test_df_attn.columns}\")\n    else:\n        test_input_sentences = test_df_attn['input_sentence'].tolist()\n        print(f\"Generating predictions for {len(test_input_sentences)} test sentences...\")\n\n        test_predictions_attn = infer_sentences_with_attention(\n            test_input_sentences, attn_model, word2idx, idx2word, device, max_len=max_len # max_len from your setup\n        )\n\n        output_df_attn = pd.DataFrame({\n            'input_sentence': test_input_sentences,\n            'prediction_sentence': test_predictions_attn\n        })\n\n        output_df_attn.to_csv(output_csv_path_attn, index=False)\n        print(f\"Predictions saved to {output_csv_path_attn}\")\n        print(\"\\nFirst 5 test predictions with attention:\")\n        print(output_df_attn.head())\n\nexcept FileNotFoundError:\n    print(f\"ERROR: Test data file not found at {test_data_path_attn}\")\nexcept Exception as e:\n    print(f\"An error occurred during test prediction generation or saving: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:14:43.623527Z","iopub.execute_input":"2025-05-08T17:14:43.624131Z","iopub.status.idle":"2025-05-08T17:15:04.898078Z","shell.execute_reply.started":"2025-05-08T17:14:43.624108Z","shell.execute_reply":"2025-05-08T17:15:04.897358Z"}},"outputs":[{"name":"stdout","text":"\nLoading test data from: /kaggle/input/test-no-target/test_no_target.csv\nGenerating predictions for 5000 test sentences...\nPredictions saved to /kaggle/working/seq2seq_with_attention_predictions.csv\n\nFirst 5 test predictions with attention:\n                                      input_sentence  \\\n0  often play you when school? in high basketball...   \n1                          what at I do. work I hard   \n2                              prefer to sit down. I   \n3  book gave the My is This yesterday. uncle a me...   \n4  are There of books English lot a in library. this   \n\n                                 prediction_sentence  \n0  how often did you play basketball when you wer...  \n1                               i work at what i do.  \n2                              i prefer to sit down.  \n3  this is the book me a book near this book yest...  \n4          there are a lot of books in this library.  \n","output_type":"stream"}],"execution_count":39},{"id":"b54e29c4","cell_type":"markdown","source":"## üìå Submission Instructions:\nSubmit your completed notebook along with two files of predictions over the test set - `seq2seq_predictions.csv` and `seq2seq_with_attention_predictions.csv`.\n\nI will run the evaluation over the held-out test set.\n\nYou should email all of these files with an email specifying the names and ids of the team (couples).\n\n‚úÖ **Good luck!**\n","metadata":{"id":"b54e29c4"}}]}