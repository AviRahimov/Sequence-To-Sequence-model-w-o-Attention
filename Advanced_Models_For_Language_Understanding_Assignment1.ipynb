{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AviRahimov/AMFLU_Assignment1/blob/main/Advanced_Models_For_Language_Understanding_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0a61948",
      "metadata": {
        "id": "f0a61948"
      },
      "source": [
        "# üîπ Assignment 1: Seq2Seq Model for Sentence Unshuffling\n",
        "In this assignment, you'll implement a basic **Sequence-to-Sequence (Seq2Seq)** neural network using PyTorch.\n",
        "\n",
        "### üéØ **Your goal:**\n",
        "Given a sentence whose words have been shuffled randomly, your model must reconstruct the original sentence.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "| Input (shuffled) | Output (original) |\n",
        "|-----------------|------------------|\n",
        "| `mat the on sat cat The` | `The cat sat on the mat` |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37546a90",
      "metadata": {
        "id": "37546a90"
      },
      "source": [
        "## üîπ Why this task?\n",
        "This simple yet non-trivial task demonstrates how language models learn word-order and syntactic structures.\n",
        "From a psycholinguistic viewpoint, sentence reconstruction taps into:\n",
        "\n",
        "- **Working memory**: The model must hold multiple words and reorder them meaningfully.\n",
        "- **Syntax and semantics**: Reordering depends on syntactic constraints and semantic coherence."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Quick Summary of PyTorch Workflow\n",
        "\n",
        "The general workflow when working with on deep learning with PyTorch usually involves these steps:\n",
        "\n",
        "1. **Prepare your data**:\n",
        "    - Define your dataset by subclassing `torch.utils.data.Dataset`.\n",
        "    - Use a `DataLoader` to iterate efficiently over the dataset in batches.\n",
        "    - Tokenization - select tokenization method and tokenize your data.\n",
        "\n",
        "2. **Define your model**:\n",
        "    - Create a model class by subclassing `nn.Module`.\n",
        "    - Define model layers in `__init__`.\n",
        "    - Define how data flows through the layers in the `forward()` method.\n",
        "\n",
        "\n",
        "3. **Training**:\n",
        "    - Select an appropriate loss function (`nn.CrossEntropyLoss`, `nn.MSELoss`, etc.).\n",
        "    - Choose an optimizer (`optim.Adam`, `optim.SGD`, etc.).\n",
        "    - **Training Loop** -- For each batch:\n",
        "        1. Pass input data through your model to produce predictions (logits).\n",
        "        2. Compute the loss w.r.t. the gold label (target).\n",
        "        3. Perform backpropagation (`loss.backward()`) to calculate gradients of all model parameters.\n",
        "        4. Update the model parameters with your optimizer (`optimizer.step()`).\n",
        "        5. Reset gradients (`optimizer.zero_grad()`).\n",
        "\n",
        "This structured workflow helps streamline model development and makes training neural networks clear and efficient.\n",
        "\n",
        "This notebook will walk you through this process - you need to learn it and the complete the missing code segment marked with a `#TODO` comment."
      ],
      "metadata": {
        "id": "FmlLBejDCw6X"
      },
      "id": "FmlLBejDCw6X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Step 0: One-time Preparations\n",
        "\n",
        "### Step 0.1: Install Python Dependencies"
      ],
      "metadata": {
        "id": "IMXO6OkGIU1j"
      },
      "id": "IMXO6OkGIU1j"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKyvKyjaIgWA",
        "outputId": "219975a9-d3b6-4792-b691-4e9396ee1ffd",
        "collapsed": true
      },
      "id": "hKyvKyjaIgWA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m177.7/363.4 MB\u001b[0m \u001b[31m145.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\n",
            "    unknown package:\n",
            "        Expected sha256 2fc8da60df463fdefa81e323eef2e36489e1c94335b5358bcb38360adf75ac9b\n",
            "             Got        da91f7ea04afb2bceda7ababe5b2ff9224b2e4ddc8dee09cbb2997f8913789b4\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7573a39",
      "metadata": {
        "id": "c7573a39"
      },
      "source": [
        "### Step 0.2: Download the Dataset\n",
        "Download the provided dataset file (`train.csv`) from the following link:\n",
        "\n",
        "[train.csv](https://drive.google.com/file/d/1eHBj_mdKjPfj_NuXy0zCG5IkQMJLGpPM/view?usp=sharing)\n",
        "\n",
        "Then upload the file to your Colab notebook or Jupyter environment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d22c22e",
      "metadata": {
        "id": "8d22c22e"
      },
      "source": [
        "## üîπ Step 1: Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a70075c2",
      "metadata": {
        "id": "a70075c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "aefa2069-a3b2-4c92-a109-e7cc752ba523"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                     input_sentence  \\\n",
              "0           0           to think need we about. That's something   \n",
              "1           1          is mountains. the up moon coming over The   \n",
              "2           2  committee. the The through Congressmen bill ra...   \n",
              "3           3            careful late I'll to never again. be be   \n",
              "4           4           please.\" gifts, \"No The said, invitation   \n",
              "\n",
              "                                     target_sentence  \n",
              "0           That's something we need to think about.  \n",
              "1          The moon is coming up over the mountains.  \n",
              "2  The Congressmen rammed the bill through commit...  \n",
              "3            I'll be careful never to be late again.  \n",
              "4           The invitation said, \"No gifts, please.\"  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c080db3-3c87-43dd-8927-f75521903d7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>input_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>to think need we about. That's something</td>\n",
              "      <td>That's something we need to think about.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>is mountains. the up moon coming over The</td>\n",
              "      <td>The moon is coming up over the mountains.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>committee. the The through Congressmen bill ra...</td>\n",
              "      <td>The Congressmen rammed the bill through commit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>careful late I'll to never again. be be</td>\n",
              "      <td>I'll be careful never to be late again.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>please.\" gifts, \"No The said, invitation</td>\n",
              "      <td>The invitation said, \"No gifts, please.\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c080db3-3c87-43dd-8927-f75521903d7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c080db3-3c87-43dd-8927-f75521903d7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c080db3-3c87-43dd-8927-f75521903d7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-06665948-66b0-44f5-bf8a-e4b4c49a525c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06665948-66b0-44f5-bf8a-e4b4c49a525c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-06665948-66b0-44f5-bf8a-e4b4c49a525c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12840,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3706,\n        \"min\": 0,\n        \"max\": 12839,\n        \"num_unique_values\": 12840,\n        \"samples\": [\n          5790,\n          11623,\n          8346\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12839,\n        \"samples\": [\n          \"for he but back a had to get few Chicago. more to Tom stay Boston wanted in days, to\",\n          \"Maybe I'll later. you see\",\n          \"I Do salesgirl? pay the\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12440,\n        \"samples\": [\n          \"Tom hasn't decided what to do.\",\n          \"Do you feel that the media presents the news fairly?\",\n          \"She called me many times.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "random_seed = 123\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c21b2edd",
      "metadata": {
        "id": "c21b2edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8d3247-fce5-48d0-d1e4-4971a52f4f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples: 11556\n",
            "Development examples: 1284\n"
          ]
        }
      ],
      "source": [
        "train_df, dev_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "print(f\"Training examples: {len(train_df)}\")\n",
        "print(f\"Development examples: {len(dev_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pedagogical Note: **Why do we split train data into training and development (dev) sets?**\n",
        "\n",
        "When developing machine learning models, we want to ensure our model not only performs well on the data it has seen during training but also generalizes effectively to **new, unseen data**.\n",
        "\n",
        "- **Training set**:  \n",
        "  Used by the model to learn patterns. This is the data your model sees repeatedly during the training process.\n",
        "\n",
        "- **Development (dev) set** *(also known as validation set)*:  \n",
        "  Used to evaluate the model's performance on unseen examples during training. By checking the model periodically against the dev set, we can identify and prevent **overfitting**‚Äîwhen the model performs excellently on training data but poorly on new examples.\n",
        "\n",
        "Thus, by splitting the data, we ensure our model truly learns generalizable patterns rather than memorizing the specific examples it trained on.\n"
      ],
      "metadata": {
        "id": "JRGMPu8eKVnI"
      },
      "id": "JRGMPu8eKVnI"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9df6d543",
      "metadata": {
        "id": "9df6d543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "759df90d-c345-40f5-8935-bc17bdcfcdaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 4403\n"
          ]
        }
      ],
      "source": [
        "# Handle Vocabulary and Tokenization\n",
        "from collections import Counter\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return sentence.lower().split()\n",
        "\n",
        "counter = Counter()\n",
        "for sentence in train_df['input_sentence']:\n",
        "    counter.update(tokenize(sentence))\n",
        "\n",
        "# Special Tokens\n",
        "PAD = '<PAD>'\n",
        "SOS = '<SOS>'\n",
        "EOS = '<EOS>'\n",
        "UNK = '<UNK>'   # to handle out-of-vocabulary words\n",
        "\n",
        "words = [PAD, SOS, EOS, UNK] + [w for w, c in counter.items() if c >= 2]\n",
        "# we maintain mapping between words (vocabulary entries) and their ids\n",
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "def encode_sentence(sentence: str, word2idx, max_len):\n",
        "    # Replace sentence string with a fixed-length list of ints (token_ids with padding)\n",
        "    tokens = tokenize(sentence)\n",
        "    token_ids = [word2idx.get(w, word2idx[UNK]) for w in tokens]\n",
        "    token_ids = token_ids[:max_len-1]\n",
        "    token_ids.append(word2idx[EOS])\n",
        "    padding = [word2idx[PAD]] * (max_len - len(token_ids))\n",
        "    return token_ids + padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9a1b859c",
      "metadata": {
        "id": "9a1b859c"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset class for sentence-to-sentence mapping\n",
        "class SentenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, word2idx, max_len):\n",
        "        # Store input and target sentences as lists of strings\n",
        "        self.input_sentences = df['input_sentence'].tolist()\n",
        "        self.target_sentences = df['target_sentence'].tolist()\n",
        "        self.word2idx = word2idx  # mapping from word to index\n",
        "        self.max_len = max_len    # maximum length of sentence (for padding)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return number of examples in the dataset\n",
        "        return len(self.input_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Encode both input and target sentences to fixed-length tensors of token IDs\n",
        "        src = encode_sentence(self.input_sentences[idx], self.word2idx, self.max_len)\n",
        "        trg = encode_sentence(self.target_sentences[idx], self.word2idx, self.max_len)\n",
        "        return torch.tensor(src), torch.tensor(trg)  # return as PyTorch tensors\n",
        "\n",
        "# Define batch size and maximum sentence length\n",
        "batch_size = 32\n",
        "max_len = 50  # All sequences will be padded/truncated to this length\n",
        "\n",
        "# Create training dataset and dataloader\n",
        "train_dataset = SentenceDataset(train_df, word2idx, max_len)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "# DataLoader loads batches from the dataset and optionally shuffles them\n",
        "\n",
        "# Create development (validation) dataset and dataloader\n",
        "dev_dataset = SentenceDataset(dev_df, word2idx, max_len)\n",
        "dev_loader = torch.utils.data.DataLoader(\n",
        "    dev_dataset, batch_size=batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one batch of (src, trg) from the DataLoader\n",
        "src_batch, trg_batch = next(iter(train_loader))\n",
        "\n",
        "# Print their shapes\n",
        "print(\"src_batch.shape =\", src_batch.shape)\n",
        "print(\"trg_batch.shape =\", trg_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm8yYkpes3u3",
        "outputId": "511f32d7-1eef-4fcf-8f76-3c175741bb9b"
      },
      "id": "Wm8yYkpes3u3",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_batch.shape = torch.Size([32, 50])\n",
            "trg_batch.shape = torch.Size([32, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Quick Reference\n",
        "\n",
        "Since this is your first encounter with PyTorch in the course, here's a short summary of essential PyTorch classes used in this notebook:\n"
      ],
      "metadata": {
        "id": "7o3Mz8zr3foD"
      },
      "id": "7o3Mz8zr3foD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "### ‚úÖ torch.utils.data.Dataset\n",
        "#### What is it?\n",
        "\n",
        "An abstract class representing your dataset. It lets you define exactly how to access and prepare each data point.\n",
        "\n",
        "#### How to use it?\n",
        "\n",
        "You subclass it and implement two methods:\n",
        "\n",
        "`__len__(self)`: returns the size of your dataset.\n",
        "\n",
        "`__getitem__(self, index)`: returns one data point (input-target pair).\n",
        "\n",
        "#### Why do we use it?\n",
        "It provides a clean way to structure your data and feed it systematically into your model.\n",
        "\n",
        "---\n",
        "### ‚úÖ torch.utils.data.DataLoader\n",
        "#### What is it?\n",
        "A utility that takes a Dataset object and provides an iterator over it.\n",
        "\n",
        "#### How to use it?\n",
        "Specify batch size, shuffle options, and more:\n",
        "\n",
        "```python\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "```\n",
        "#### Why do we use it?\n",
        "It handles batching, shuffling, and efficient parallel data loading automatically‚Äîmaking your training loop concise and efficient.\n",
        "\n",
        "---\n",
        "### ‚úÖ torch.nn.Module\n",
        "#### What is it?\n",
        "The base class for all neural network models in PyTorch. Every model you build inherits from it.\n",
        "\n",
        "#### How to use it?\n",
        "You subclass it, define your layers in the constructor (`__init__`), and specify the forward pass in the `forward()` method:\n",
        "\n",
        "```python\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.linear = nn.Linear(10, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "```\n",
        "#### Why do we use it?\n",
        "It manages model parameters, handles the forward computation, and simplifies tasks such as moving models to GPU or tracking gradients automatically.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hKLOmTr0BHyk"
      },
      "id": "hKLOmTr0BHyk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Step 2: Define Model"
      ],
      "metadata": {
        "id": "VlTEAM4y3FA0"
      },
      "id": "VlTEAM4y3FA0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building blocks - Enocder and Decoder"
      ],
      "metadata": {
        "id": "DuXH8zUee6Ud"
      },
      "id": "DuXH8zUee6Ud"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6c990ab2",
      "metadata": {
        "id": "6c990ab2"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        # TODO: define layers used in the encoder, e.g. embedding and LSTM layers\n",
        "\n",
        "        # Setting the embedding layer for the encoder with size of vocabulary as passed in the input (vocab_size)\n",
        "        # And with dimesion of embedding_size\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
        "\n",
        "        # Add Long Short Term Memory layer with input size = embedding_size, hidden size as named, number of layers\n",
        "        # equals to 2 which is the default, and batch first is true since the shape of the src_batch was [32,50]\n",
        "        # which indicated that the batch size comes first\n",
        "        self.lstm = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=2, batch_first=True)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        \"\"\"\n",
        "        input: (seq_len, batch_size) - token indices for input sentence\n",
        "        hidden: (1, batch_size, hidden_size) - initial hidden state\n",
        "        Returns:\n",
        "            output: all hidden states for the input sequence\n",
        "            hidden: final hidden state\n",
        "        \"\"\"\n",
        "        # TODO: implement the forward pass here\n",
        "        embedding = self.embedding(input)\n",
        "        output, hidden = self.lstm(embedding)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(1, batch_size, hidden_size)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        # TODO: define layers used in the decoder, e.g. embedding, LSTM and linear layers\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=2, batch_first=True)\n",
        "\n",
        "        self.out = nn.Linear(in_features=hidden_size, out_features=vocab_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        \"\"\"\n",
        "        input: (batch_size) - current token index at this decoding step\n",
        "        hidden: (1, batch_size, hidden_size) - current hidden state\n",
        "        Returns:\n",
        "            output: prediction for the next word (before softmax)\n",
        "            hidden: updated hidden state\n",
        "        \"\"\"\n",
        "        # TODO: Embed the input token, run one step of the RNN, generate output\n",
        "        embedding = self.embedding(input)\n",
        "        out, hidden = self.lstm(embedding)\n",
        "        output = self.out(out)\n",
        "        return output, hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "08f70b0d",
      "metadata": {
        "id": "08f70b0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bbbd84-a233-45d3-c65b-8a866f74f68c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([32, 50, 128])\n",
            "Decoder output shape: torch.Size([32, 4403])\n"
          ]
        }
      ],
      "source": [
        "# Define Encoder & Decoder\n",
        "embedding_size = 64\n",
        "hidden_size = 128\n",
        "\n",
        "encoder = EncoderRNN(vocab_size, embedding_size, hidden_size)\n",
        "decoder = DecoderRNN(vocab_size, embedding_size, hidden_size)\n",
        "\n",
        "# Sanity Checks\n",
        "sample_input, sample_target = next(iter(train_loader))\n",
        "encoder_hidden = encoder.init_hidden(sample_input.size(0))\n",
        "encoder_output, encoder_hidden = encoder(sample_input, encoder_hidden)\n",
        "\n",
        "decoder_input = torch.tensor([word2idx[SOS]] * sample_input.size(0))\n",
        "decoder_hidden = encoder_hidden\n",
        "\n",
        "decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "print(\"Encoder output shape:\", encoder_output.shape)\n",
        "print(\"Decoder output shape:\", decoder_output.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq model that wraps Encoder and Decoder together"
      ],
      "metadata": {
        "id": "jQLknjFt-5bg"
      },
      "id": "jQLknjFt-5bg"
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, sos_idx, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.sos_idx = sos_idx\n",
        "        self.device = device  # needed for creating new tensors like hidden states\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \"\"\"\n",
        "        src: (batch_size, seq_len) - input sentence (shuffled)\n",
        "        trg: (batch_size, seq_len) - target sentence (original)\n",
        "        Returns:\n",
        "            outputs: tensor of shape (batch_size, seq_len, vocab_size)\n",
        "        \"\"\"\n",
        "        batch_size, trg_len = trg.shape\n",
        "        vocab_size = self.decoder.out.out_features\n",
        "\n",
        "        # Create an empty tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size, trg_len, vocab_size, device=self.device)\n",
        "\n",
        "        # Transpose inputs to match (seq_len, batch_size)\n",
        "        src = src.T\n",
        "        trg = trg.T\n",
        "\n",
        "        # Initialize hidden state on correct device\n",
        "        hidden = self.encoder.init_hidden(batch_size)\n",
        "\n",
        "        # Encode the input sentence\n",
        "        _, hidden = self.encoder(src, hidden)\n",
        "\n",
        "        # Start decoding with the <SOS> token\n",
        "        input = torch.full((batch_size,), self.sos_idx, device=self.device)\n",
        "\n",
        "        for t in range(trg_len):\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            outputs[:, t, :] = output\n",
        "            input = trg[t]  # teacher forcing: feed the true token at each step\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "JdusuF9w_Ea4"
      },
      "id": "JdusuF9w_Ea4",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Step 3: Training"
      ],
      "metadata": {
        "id": "WAmJH-5feIkb"
      },
      "id": "WAmJH-5feIkb"
    },
    {
      "cell_type": "code",
      "source": [
        "# define the training-loop function\n",
        "def train_model(model, train_loader, dev_loader, optimizer, criterion, device, num_epochs=10):\n",
        "    model.to(device)\n",
        "    train_losses = []\n",
        "    dev_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for src, trg in train_loader:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, trg)\n",
        "\n",
        "            # output: (batch, seq_len, vocab_size)\n",
        "            # trg: (batch, seq_len)\n",
        "            output = output.view(-1, output.shape[-1])  # shape: (batch * seq_len, vocab_size)\n",
        "            trg = trg.view(-1)                          # shape: (batch * seq_len)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        train_losses.append(epoch_loss / len(train_loader))\n",
        "\n",
        "        # Evaluate on dev set\n",
        "        model.eval()\n",
        "        dev_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for src, trg in dev_loader:\n",
        "                src, trg = src.to(device), trg.to(device)\n",
        "                output = model(src, trg)\n",
        "                output = output.view(-1, output.shape[-1])\n",
        "                trg = trg.view(-1)\n",
        "                loss = criterion(output, trg)\n",
        "                dev_loss += loss.item()\n",
        "\n",
        "        dev_losses.append(dev_loss / len(dev_loader))\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {train_losses[-1]:.4f} | Dev Loss: {dev_losses[-1]:.4f}\")\n",
        "\n",
        "    return train_losses, dev_losses\n"
      ],
      "metadata": {
        "id": "0lUGBZ7pd0Rw"
      },
      "id": "0lUGBZ7pd0Rw",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Seq2Seq(encoder, decoder, word2idx[SOS], device)\n",
        "\n",
        "# Choose optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word2idx[PAD])\n",
        "\n",
        "# Run training\n",
        "train_losses, dev_losses = train_model(\n",
        "    model, train_loader, dev_loader,\n",
        "    optimizer, criterion, device,\n",
        "    num_epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "AqiWK2_-fOWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6553317-0778-4e58-dfa9-ea18fb9ad3e3"
      },
      "id": "AqiWK2_-fOWF",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 5.8542 | Dev Loss: 5.2748\n",
            "Epoch 2 | Train Loss: 5.3629 | Dev Loss: 4.9991\n",
            "Epoch 3 | Train Loss: 5.0838 | Dev Loss: 4.7703\n",
            "Epoch 4 | Train Loss: 4.8709 | Dev Loss: 4.6115\n",
            "Epoch 5 | Train Loss: 4.7129 | Dev Loss: 4.5100\n",
            "Epoch 6 | Train Loss: 4.5955 | Dev Loss: 4.4315\n",
            "Epoch 7 | Train Loss: 4.4963 | Dev Loss: 4.3811\n",
            "Epoch 8 | Train Loss: 4.4190 | Dev Loss: 4.3377\n",
            "Epoch 9 | Train Loss: 4.3510 | Dev Loss: 4.3080\n",
            "Epoch 10 | Train Loss: 4.2924 | Dev Loss: 4.2826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper - loss visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(train_losses, dev_losses):\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(dev_losses, label='Dev Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Dev Loss over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_losses(train_losses, dev_losses)"
      ],
      "metadata": {
        "id": "k63dQnCoh3Zn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "854dacab-5f8b-4c07-f6be-d1b1a3884136"
      },
      "id": "k63dQnCoh3Zn",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pedagogical Note: Interpreting the Loss Plots üîç\n",
        "\n",
        "After training completes, you'll see two curves:\n",
        "\n",
        "- **Train Loss**: How well the model fits the training data.\n",
        "- **Dev Loss**: How well the model generalizes to unseen (validation) data.\n",
        "\n",
        "Ideally:\n",
        "- Both curves should **decrease over time**.\n",
        "- A small gap between them indicates **good generalization**.\n",
        "- If train loss decreases but dev loss increases, your model may be **overfitting**.\n",
        "\n",
        "Use these curves to decide if your model is learning stably and when to stop training.\n"
      ],
      "metadata": {
        "id": "aO0t5R_HkEvF"
      },
      "id": "aO0t5R_HkEvF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Inference\n",
        "Now that you have a trained model, you can use it to solve your task on any new data points.\n",
        "\n",
        "Complete the code below for implementing a inference function for the model."
      ],
      "metadata": {
        "id": "fSXqwoPDndhF"
      },
      "id": "fSXqwoPDndhF"
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_sentences(shuffled_sentences, model, word2idx, idx2word, device, max_len=50):\n",
        "    \"\"\"\n",
        "    Generate predicted (unshuffled) sentences from a list of shuffled input sentences.\n",
        "\n",
        "    Args:\n",
        "        shuffled_sentences (List[str]): Sentences with words in randomized order.\n",
        "        model (Seq2Seq): Trained encoder-decoder model.\n",
        "        word2idx (Dict[str, int]): Mapping from words to vocabulary indices.\n",
        "        idx2word (Dict[int, str]): Mapping from indices to words.\n",
        "        device (torch.device): CPU or CUDA device for inference.\n",
        "        max_len (int): Maximum sentence length to decode.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: Model's predicted sentences (as plain strings).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    sos_idx = word2idx['<SOS>']\n",
        "    eos_idx = word2idx['<EOS>']\n",
        "    pad_idx = word2idx['<PAD>']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sentence in shuffled_sentences:\n",
        "            # TODO\n",
        "            predicted_sentence: str = ...\n",
        "            predictions.append(predicted_sentence)\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "LOlykSQOoa_R"
      },
      "id": "LOlykSQOoa_R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now, use the above inference function to generate prediction for the **test set**. You are provided with the test set shuffled sentences in [this downloadable file](https://drive.google.com/file/d/178mEesTW89Ooz_f5bb6sHBHjAkG4DWMV/view?usp=sharing). In your submission, you should run the inference function of the provided list of shuffled sentences, to attain a `predicted_test.csv` file. Typically, these predictions over the test set will be evaluated against their annotated labels (targets).  \n",
        "\n",
        "If you want to assess the quality of current trained model, you can run inference on the dev set and evaluate on it using the function below:"
      ],
      "metadata": {
        "id": "Ddv1mOKWqA9p"
      },
      "id": "Ddv1mOKWqA9p"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_sentence_predictions(predictions, targets):\n",
        "    \"\"\"\n",
        "    Compute exact match accuracy between predicted and target sentences (as strings).\n",
        "    Args:\n",
        "        predictions (List[str])\n",
        "        targets (List[str])\n",
        "    Returns:\n",
        "        accuracy (float): percentage of exact string matches\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = len(predictions)\n",
        "    for pred, true in zip(predictions, targets):\n",
        "        if pred.strip() == true.strip():\n",
        "            correct += 1\n",
        "    accuracy = correct / total * 100\n",
        "    print(f\"Exact match accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "SE0shbcytAE1"
      },
      "id": "SE0shbcytAE1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÅ Stage 2: Add Attention to Your Seq2Seq Model\n",
        "\n",
        "In this stage, you'll implement a new model: **`Seq2SeqWithAttention`**.  \n",
        "The goal is to improve your decoder by allowing it to \"attend\" to relevant parts of the encoder's outputs at each decoding step.\n",
        "\n",
        "### üß† Why Attention?\n",
        "The encoder compresses the entire input sentence into a single hidden state. This limits performance, especially on long sentences.\n",
        "\n",
        "With attention, the decoder **dynamically focuses on different encoder outputs**, depending on what it's trying to generate.\n",
        "\n",
        "---\n",
        "\n",
        "### üîß What You Need to Implement:\n",
        "You will create a new class `Seq2SeqWithAttention`, similar to `Seq2Seq`, but with the following differences:\n",
        "\n",
        "1. At each decoding step, compute **attention scores** over all encoder hidden states.\n",
        "2. Use those scores to compute a **context vector** (weighted sum of encoder outputs).\n",
        "3. Feed the context vector into the decoder along with the embedding of the current input token.\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Tip: Dot-Product Attention\n",
        "A simple form of attention you can implement is dot-product attention:\n",
        "\n",
        "```python\n",
        "score_t = dot(h_dec_t, h_enc_i) weights = softmax(score_t over i) context_t = sum_i weights[i] * h_enc_i\n",
        "```\n",
        "\n",
        "You'll apply this at every decoder time step.\n"
      ],
      "metadata": {
        "id": "m9PRjqHkt50Z"
      },
      "id": "m9PRjqHkt50Z"
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqWithAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder, sos_idx, device):\n",
        "        super(Seq2SeqWithAttention, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.sos_idx = sos_idx\n",
        "        self.device = device\n",
        "\n",
        "        # TODO: If needed, add additional layers for attention (e.g., linear projection)\n",
        "\n",
        "    def compute_attention(self, decoder_hidden, encoder_outputs):\n",
        "        \"\"\"\n",
        "        decoder_hidden: (1, batch_size, hidden_size)\n",
        "        encoder_outputs: (seq_len, batch_size, hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context vector: (batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        # TODO: implement dot-product attention or another variant\n",
        "        # Steps:\n",
        "        # 1. Compute attention scores: dot(decoder_hidden, encoder_outputs)\n",
        "        # 2. Apply softmax to get attention weights\n",
        "        # 3. Compute context vector: weighted sum of encoder_outputs\n",
        "        return context_vector\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \"\"\"\n",
        "        src: (batch_size, seq_len)\n",
        "        trg: (batch_size, seq_len)\n",
        "        Returns:\n",
        "            outputs: (batch_size, seq_len, vocab_size)\n",
        "        \"\"\"\n",
        "        batch_size, trg_len = trg.shape\n",
        "        vocab_size = self.decoder.out.out_features\n",
        "        outputs = torch.zeros(batch_size, trg_len, vocab_size, device=self.device)\n",
        "\n",
        "        src = src.T\n",
        "        trg = trg.T\n",
        "\n",
        "        hidden = self.encoder.init_hidden(batch_size)\n",
        "        encoder_outputs, hidden = self.encoder(src, hidden)  # encoder_outputs: (seq_len, batch_size, hidden_size)\n",
        "\n",
        "        input_token = torch.full((batch_size,), self.sos_idx, device=self.device)\n",
        "\n",
        "        for t in range(trg_len):\n",
        "            # TODO: Compute context vector based on current hidden and encoder_outputs\n",
        "            context = self.compute_attention(hidden, encoder_outputs)\n",
        "\n",
        "            # TODO: Modify decoder forward to accept and use the context vector\n",
        "            # Hint: You may need to add context to the input embedding, or to the hidden state\n",
        "            output, hidden = self.decoder(input_token, hidden, context)\n",
        "\n",
        "            outputs[:, t, :] = output\n",
        "            input_token = trg[t]  # teacher forcing\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "nPvAmc_euarf"
      },
      "id": "nPvAmc_euarf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù What You Need to Complete\n",
        "\n",
        "- Implement the `compute_attention()` method to compute a context vector from encoder outputs given the current (decoder) hidden state.\n",
        "- Update your `DecoderRNN` class so that it accepts and uses a context vector at every step:\n",
        "    - One option is to **concatenate** the context vector with the embedded input token before passing it to the RNN.\n",
        "    - Alternatively, you can feed the context into a projection layer together with the decoder hidden state.\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Tip: Updated Decoder Signature\n",
        "\n",
        "You may need to rewrite your decoder to look like:\n",
        "\n",
        "```python\n",
        "def forward(self, input_token, hidden, context_vector):\n",
        "    ...\n",
        "```\n",
        "---\n",
        "> üí° **Note on Attention Implementation**\n",
        "\n",
        "You are given flexibility in how you choose to implement the attention mechanism.\n",
        "\n",
        "You may:\n",
        "- Implement the **basic dot-product attention** we discussed in class.\n",
        "- Or, explore a more expressive variant by adding a **linear projection** to the decoder hidden state or the encoder outputs ‚Äî borrowing an idea from self-attention in Transformers.\n",
        "\n",
        "As long as your implementation uses the decoder hidden state to compute attention over the encoder outputs and forms a context vector, you're free to experiment and design the solution that makes most sense to you.\n"
      ],
      "metadata": {
        "id": "3Fm5tMpGvBP1"
      },
      "id": "3Fm5tMpGvBP1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 - Evaluate and Compare\n",
        "\n",
        "In this stage, you should use your adapted `Seq2SeqWithAttention` model, train it and evaluate its performance (on the dev set).  "
      ],
      "metadata": {
        "id": "lsGSMPTxwj4a"
      },
      "id": "lsGSMPTxwj4a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and Train a Seq2SeqWithAttention model\n",
        "# TODO"
      ],
      "metadata": {
        "id": "RRjxs544y1NK"
      },
      "id": "RRjxs544y1NK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b54e29c4",
      "metadata": {
        "id": "b54e29c4"
      },
      "source": [
        "## üìå Submission Instructions:\n",
        "Submit your completed notebook along with two files of predictions over the test set - `seq2seq_predictions.csv` and `seq2seq_with_attention_predictions.csv`.\n",
        "\n",
        "I will run the evaluation over the held-out test set.\n",
        "\n",
        "You should email all of these files with an email specifying the names and ids of the team (couples).\n",
        "\n",
        "‚úÖ **Good luck!**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7o3Mz8zr3foD"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}